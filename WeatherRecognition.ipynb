{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8291fd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet101V2\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7422e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images_from_dir(directory):\n",
    "    images = []\n",
    "    for folder in folder_names:\n",
    "        folder_path = os.path.join(directory, folder)\n",
    "        print(folder_path)\n",
    "        for filename in os.listdir(folder_path):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            print(image_path)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Error: Could not read image file {image_path}\")\n",
    "                continue\n",
    "            print(image.shape)\n",
    "            image = cv2.resize(image, (224, 224))\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Convert from BGR to RGB\n",
    "            images.append((image, int(folder)))  # Store the image and its class label (0 or 1) as a tuple\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db1b86ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['dew', 'fogsmog', 'frost', 'glaze', 'hail', 'lightning' , 'rain', 'rainbow', 'rime', 'sandstorm', 'snow']\n",
    "folder_names = [\"0\",     \"1\",      \"2\",     \"3\",    \"4\",      \"5\",        \"6\",      \"7\",      \"8\",      \"9\",      \"10\" ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24acbfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = read_images_from_dir('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4872d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([np.asarray(Image.fromarray(t[0])) for t in all_data])\n",
    "y = np.array([t[1] for t in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f7cabba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6860\n",
      "6860\n",
      "(6860, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(len(x))\n",
    "print(len(y))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3764d78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6860, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "i=0\n",
    "for i in range(len(x)):\n",
    "    x[i] = preprocess_input(x[i])\n",
    "    i += 1\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "698e58eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4116, 224, 224, 3) (4116,)\n",
      "(2744, 224, 224, 3) (2744,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3651603498542274"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=0)\n",
    "\n",
    "train_features = x_train.reshape(x_train.shape[0], -1)\n",
    "test_features = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(train_features, y_train)\n",
    "clf.score(test_features, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d84c12f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res50Built(Train, labelTrain, Test, labelTest, imageDim):\n",
    "    epochs = 40\n",
    "    num_classes = 11\n",
    "    model = Sequential()\n",
    "    pretrained_model = tf.keras.applications.ResNet50(include_top=False, \n",
    "                                                input_shape = (224, 224, 3),\n",
    "                                                pooling='avg' , \n",
    "                                                classes=11,\n",
    "                                                weights='imagenet')\n",
    "    for layer in pretrained_model.layers:\n",
    "      layer.trainable=False\n",
    "\n",
    "    model.add(pretrained_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        'sgd',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=[tf.keras.metrics.AUC(name=\"accuracy\"), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()],\n",
    "    )\n",
    "    model.fit(\n",
    "        Train,\n",
    "        to_categorical(labelTrain),\n",
    "        epochs=epochs,\n",
    "        validation_data=(Test, to_categorical(labelTest)),\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    predictions = model.predict(Test)\n",
    "    # print(predictions)\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    print('sum of labeltest: ', sum([labelTest[i] == predictions[i] for i in range(len(predictions))]))\n",
    "    print('en of label test: ', len(labelTest))\n",
    "    precision = precision_score(labelTest, predictions, average='micro')\n",
    "    recall = recall_score(labelTest, predictions, average='micro')\n",
    "    fscore = f1_score(labelTest, predictions, average='micro')\n",
    "    print('precision: ', precision, 'recall: ', recall, \"f1 score: \", fscore)\n",
    "    # print(predictions)\n",
    "    cm = confusion_matrix(labelTest, predictions)\n",
    "    print('cm: ', cm)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3ec120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5488, 224, 224, 3) (1372, 224, 224, 3)\n",
      "Epoch 1/40\n",
      "172/172 [==============================] - 189s 1s/step - loss: 0.9333 - accuracy: 0.9553 - precision_5: 0.8306 - recall_5: 0.5556 - val_loss: 0.6100 - val_accuracy: 0.9805 - val_precision_5: 0.8619 - val_recall_5: 0.7187\n",
      "Epoch 2/40\n",
      "172/172 [==============================] - 187s 1s/step - loss: 0.5283 - accuracy: 0.9850 - precision_5: 0.8813 - recall_5: 0.7697 - val_loss: 0.5889 - val_accuracy: 0.9799 - val_precision_5: 0.8487 - val_recall_5: 0.7522\n",
      "Epoch 3/40\n",
      "172/172 [==============================] - 186s 1s/step - loss: 0.4364 - accuracy: 0.9898 - precision_5: 0.8981 - recall_5: 0.8110 - val_loss: 0.5169 - val_accuracy: 0.9848 - val_precision_5: 0.8787 - val_recall_5: 0.7813\n",
      "Epoch 4/40\n",
      "172/172 [==============================] - 187s 1s/step - loss: 0.3736 - accuracy: 0.9926 - precision_5: 0.9134 - recall_5: 0.8382 - val_loss: 0.4854 - val_accuracy: 0.9860 - val_precision_5: 0.8813 - val_recall_5: 0.8061\n",
      "Epoch 5/40\n",
      "172/172 [==============================] - 187s 1s/step - loss: 0.3296 - accuracy: 0.9943 - precision_5: 0.9272 - recall_5: 0.8612 - val_loss: 0.5036 - val_accuracy: 0.9845 - val_precision_5: 0.8617 - val_recall_5: 0.8083\n",
      "Epoch 6/40\n",
      "172/172 [==============================] - 186s 1s/step - loss: 0.2941 - accuracy: 0.9953 - precision_5: 0.9373 - recall_5: 0.8766 - val_loss: 0.4766 - val_accuracy: 0.9862 - val_precision_5: 0.8718 - val_recall_5: 0.8127\n",
      "Epoch 7/40\n",
      "172/172 [==============================] - 2079s 12s/step - loss: 0.2651 - accuracy: 0.9963 - precision_5: 0.9449 - recall_5: 0.8912 - val_loss: 0.4514 - val_accuracy: 0.9865 - val_precision_5: 0.8733 - val_recall_5: 0.8185\n",
      "Epoch 8/40\n",
      "172/172 [==============================] - 185s 1s/step - loss: 0.2353 - accuracy: 0.9973 - precision_5: 0.9493 - recall_5: 0.9073 - val_loss: 0.4724 - val_accuracy: 0.9856 - val_precision_5: 0.8732 - val_recall_5: 0.8134\n",
      "Epoch 9/40\n",
      "172/172 [==============================] - 186s 1s/step - loss: 0.2193 - accuracy: 0.9977 - precision_5: 0.9521 - recall_5: 0.9094 - val_loss: 0.5063 - val_accuracy: 0.9838 - val_precision_5: 0.8705 - val_recall_5: 0.8032\n",
      "Epoch 10/40\n",
      "172/172 [==============================] - 187s 1s/step - loss: 0.1994 - accuracy: 0.9983 - precision_5: 0.9608 - recall_5: 0.9198 - val_loss: 0.4411 - val_accuracy: 0.9876 - val_precision_5: 0.8850 - val_recall_5: 0.8360\n",
      "Epoch 11/40\n",
      "172/172 [==============================] - 187s 1s/step - loss: 0.1819 - accuracy: 0.9986 - precision_5: 0.9635 - recall_5: 0.9339 - val_loss: 0.4627 - val_accuracy: 0.9864 - val_precision_5: 0.8728 - val_recall_5: 0.8302\n",
      "Epoch 12/40\n",
      "172/172 [==============================] - 396s 2s/step - loss: 0.1682 - accuracy: 0.9988 - precision_5: 0.9681 - recall_5: 0.9393 - val_loss: 0.4279 - val_accuracy: 0.9885 - val_precision_5: 0.8806 - val_recall_5: 0.8389\n",
      "Epoch 13/40\n",
      "172/172 [==============================] - 190s 1s/step - loss: 0.1518 - accuracy: 0.9991 - precision_5: 0.9727 - recall_5: 0.9470 - val_loss: 0.4570 - val_accuracy: 0.9858 - val_precision_5: 0.8705 - val_recall_5: 0.8280\n",
      "Epoch 14/40\n",
      "172/172 [==============================] - 195s 1s/step - loss: 0.1414 - accuracy: 0.9993 - precision_5: 0.9739 - recall_5: 0.9513 - val_loss: 0.4396 - val_accuracy: 0.9869 - val_precision_5: 0.8814 - val_recall_5: 0.8397\n",
      "Epoch 15/40\n",
      "172/172 [==============================] - 195s 1s/step - loss: 0.1283 - accuracy: 0.9994 - precision_5: 0.9799 - recall_5: 0.9586 - val_loss: 0.4747 - val_accuracy: 0.9854 - val_precision_5: 0.8658 - val_recall_5: 0.8324\n",
      "Epoch 16/40\n",
      "172/172 [==============================] - 192s 1s/step - loss: 0.1194 - accuracy: 0.9996 - precision_5: 0.9801 - recall_5: 0.9619 - val_loss: 0.4589 - val_accuracy: 0.9864 - val_precision_5: 0.8778 - val_recall_5: 0.8324\n",
      "Epoch 17/40\n",
      "172/172 [==============================] - 187s 1s/step - loss: 0.1099 - accuracy: 0.9997 - precision_5: 0.9832 - recall_5: 0.9679 - val_loss: 0.4406 - val_accuracy: 0.9872 - val_precision_5: 0.8782 - val_recall_5: 0.8411\n",
      "Epoch 18/40\n",
      "172/172 [==============================] - 189s 1s/step - loss: 0.1014 - accuracy: 0.9997 - precision_5: 0.9858 - recall_5: 0.9730 - val_loss: 0.4348 - val_accuracy: 0.9874 - val_precision_5: 0.8776 - val_recall_5: 0.8469\n",
      "Epoch 19/40\n",
      "172/172 [==============================] - 190s 1s/step - loss: 0.0926 - accuracy: 0.9998 - precision_5: 0.9871 - recall_5: 0.9754 - val_loss: 0.4456 - val_accuracy: 0.9866 - val_precision_5: 0.8797 - val_recall_5: 0.8418\n",
      "Epoch 20/40\n",
      "172/172 [==============================] - 191s 1s/step - loss: 0.0889 - accuracy: 0.9998 - precision_5: 0.9884 - recall_5: 0.9781 - val_loss: 0.4590 - val_accuracy: 0.9854 - val_precision_5: 0.8769 - val_recall_5: 0.8462\n",
      "Epoch 21/40\n",
      "172/172 [==============================] - 190s 1s/step - loss: 0.0826 - accuracy: 0.9999 - precision_5: 0.9893 - recall_5: 0.9807 - val_loss: 0.4474 - val_accuracy: 0.9871 - val_precision_5: 0.8832 - val_recall_5: 0.8491\n",
      "Epoch 22/40\n",
      "172/172 [==============================] - 193s 1s/step - loss: 0.0759 - accuracy: 0.9999 - precision_5: 0.9916 - recall_5: 0.9841 - val_loss: 0.4556 - val_accuracy: 0.9862 - val_precision_5: 0.8732 - val_recall_5: 0.8433\n",
      "Epoch 23/40\n",
      "172/172 [==============================] - 200s 1s/step - loss: 0.0720 - accuracy: 0.9999 - precision_5: 0.9925 - recall_5: 0.9856 - val_loss: 0.4471 - val_accuracy: 0.9859 - val_precision_5: 0.8818 - val_recall_5: 0.8484\n",
      "Epoch 24/40\n",
      "172/172 [==============================] - 200s 1s/step - loss: 0.0662 - accuracy: 0.9999 - precision_5: 0.9927 - recall_5: 0.9876 - val_loss: 0.4509 - val_accuracy: 0.9861 - val_precision_5: 0.8761 - val_recall_5: 0.8404\n",
      "Epoch 25/40\n",
      " 49/172 [=======>......................] - ETA: 1:59 - loss: 0.0615 - accuracy: 1.0000 - precision_5: 0.9936 - recall_5: 0.9892"
     ]
    }
   ],
   "source": [
    "#splitting the dataset into train and test set by k-fold cross validation and training data using ResNet50\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)  #5-fold cross validation \n",
    "fold = 1\n",
    "accuracies = []\n",
    "for train_index, test_index in kf.split(x):\n",
    "\n",
    "    x_train, x_test = x[train_index], x[test_index]  #training and testing data \n",
    "    y_train, y_test = y[train_index], y[test_index]  #training and testing labels\n",
    "    \n",
    "    \n",
    "    print(x_train.shape, x_test.shape)\n",
    "    \n",
    "    x_train2 = x_train.reshape(-1, 224, 224, 3)\n",
    "    x_test2 = x_test.reshape(-1, 224, 224, 3)\n",
    "    predictions = res50Built(x_train2, y_train, x_test2, y_test, 3)\n",
    "    accuracy = accuracy_score(y_test, predictions, average='micro')\n",
    "    print('Fold {}: accuracy = {:.2f}%'.format(fold, accuracy*100))\n",
    "    \n",
    "    # Add the accuracy to the list of accuracies\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    fold += 1\n",
    "\n",
    "# Print the mean and standard deviation of the accuracies\n",
    "\n",
    "print('Mean accuracy = {:.2f}%'.format(np.mean(accuracies)*100))\n",
    "print('Std deviation = {:.2f}%'.format(np.std(accuracies)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ebf4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(x):\n",
    "\n",
    "    x_train, x_test = x[train_index], x[test_index]  #training and testing data for independent variables \n",
    "    y_train, y_test = y[train_index], y[test_index]  #training and testing data for dependent variable\n",
    "    \n",
    "    train_features = x_train.reshape(x_train.shape[0], -1)\n",
    "    test_features = x_test.reshape(x_test.shape[0], -1)\n",
    "    #fitting linear regression to the training set    \n",
    "    regressor = LinearRegression()   #creating an object of LinearRegression class \n",
    "    regressor.fit(train_features, y_train)  #fitting the linear regression model to our training set\n",
    "    \n",
    "    #predicting the test set results    \n",
    "    y_pred = regressor.predict(test_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19e856a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.14897808e+09, -2.66140052e+09,  1.22580323e+10, ...,\n",
       "       -1.33950814e+10,  1.30502438e+10,  5.96462554e+09])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf0f00a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envir",
   "language": "python",
   "name": "envir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
